{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff82abcb-2ad2-4f6f-ac3e-d1353a6dcc6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# INM706 - Deep Learning for Sequence Analysis\n",
    "\n",
    "Authors: Laerte Adami - Elisa Troschka\n",
    "\n",
    "Source: \n",
    "- https://towardsdatascience.com/a-comprehensive-guide-to-neural-machine-translation-using-seq2sequence-modelling-using-pytorch-41c9b84ba350#30b6\n",
    "- https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#evaluation\n",
    "\n",
    "Blue Score:\n",
    "- https://towardsdatascience.com/foundations-of-nlp-explained-bleu-score-and-wer-metrics-1a5ba06d812b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a514fdd-4d0a-41b8-8aaa-6b92e49c9349",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages/torchtext/_torchtext.so: undefined symbol: _ZNK3c104Type14isSubtypeOfExtERKSt10shared_ptrIS0_EPSo",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_90162/2227551286.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcandidate_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'The'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'on'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'the'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'table'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m references_corpus = [\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlegacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_extension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_init_extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages/torchtext/vocab/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m from .vocab_factory import (\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages/torchtext/vocab/vocab_factory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m from torchtext._torchtext import (\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mVocab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mVocabPybind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: /opt/apps/flight/env/conda+jupyter/lib/python3.9/site-packages/torchtext/_torchtext.so: undefined symbol: _ZNK3c104Type14isSubtypeOfExtERKSt10shared_ptrIS0_EPSo"
     ]
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "candidate_corpus = [['The', 'cat', 'is', 'on','the','table']]\n",
    "references_corpus = [\n",
    "    \n",
    "        [['The', 'cat', 'is', 'on','the','table']]]\n",
    "\n",
    "print(len(candidate_corpus))\n",
    "print(len(references_corpus))\n",
    "    \n",
    "                    \n",
    "bleu_score(candidate_corpus, references_corpus,max_n=4, weights=[0.25, 0.25, 0.25,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d08d81c-49ae-4da4-97e6-ca5e10e9a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functionalities\n",
    "from Utilities.lstmHandler import EncoderLSTM, DecoderLSTM, AttentionDecoderLSTM\n",
    "from Utilities.modelHandler import LSTModel\n",
    "from Utilities.LanguageDataset import LanguageDataset\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss as CEL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "plt.rcParams['font.size'] = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30a2cdb8-53e9-4080-a423-2319921631eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocabulary size for training: 530\n",
      "Italian vocabulary size for training: 769\n",
      "--------------------------------------------\n",
      "Train set dimension: 355\n",
      "Val set dimension: 36\n",
      "Test set dimension: 109\n"
     ]
    }
   ],
   "source": [
    "## DATASET PARAMETERS ##\n",
    "data_path = \"Data/eng_ita.tsv\"\n",
    "limit_data = 500\n",
    "start_token = '<BoS>'\n",
    "end_token = '<EoS>'\n",
    "seq_len = 10\n",
    "embedding_size = 256\n",
    "batch_size = 100\n",
    "\n",
    "# Import datasets\n",
    "dataset = LanguageDataset(data_path = data_path, start_token = start_token, end_token = end_token, seq_len = seq_len, limit_data = limit_data)\n",
    "train_set, val_set, test_set = dataset.get_datasets()\n",
    "\n",
    "end_index = dataset.from_ita[end_token]\n",
    "start_index = dataset.from_ita[start_token]\n",
    "\n",
    "# Create dataloaders\n",
    "trainloader = DataLoader(train_set, batch_size = batch_size)\n",
    "valloader = DataLoader(val_set, batch_size = batch_size)\n",
    "testloader = DataLoader(test_set, batch_size = batch_size)\n",
    "\n",
    "# Vocabulary for BLUE score\n",
    "blue_voc = dataset.blue_score_test\n",
    "\n",
    "print(\"English vocabulary size for training: {}\".format(dataset.eng_voc_size))\n",
    "print(\"Italian vocabulary size for training: {}\".format(dataset.ita_voc_size))\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"Train set dimension: {}\".format(train_set.__len__()))\n",
    "print(\"Val set dimension: {}\".format(val_set.__len__()))\n",
    "print(\"Test set dimension: {}\".format(test_set.__len__()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ca830d-9527-4b2d-a86f-e4968a789e89",
   "metadata": {},
   "source": [
    "## Model defition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0674a3c-32e3-4d42-88e0-b233d86412dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderLSTM(vocabulary_size = dataset.eng_voc_size,\n",
    "                     embedding_size = embedding_size,\n",
    "                     num_layers = 1, \n",
    "                     bidirectional = False)\n",
    "\n",
    "#decoder = DecoderLSTM(vocabulary_size = dataset.ita_voc_size,\n",
    "#                     embedding_size = embedding_size,\n",
    "#                     num_layers = 1, \n",
    "#                     bidirectional = False)\n",
    "\n",
    "decoder = AttentionDecoderLSTM(vocabulary_size = dataset.ita_voc_size,\n",
    "                     embedding_size = embedding_size,\n",
    "                     seq_len = dataset.seq_len,\n",
    "                     num_layers = 1, \n",
    "                     bidirectional = False)\n",
    "\n",
    "loss_func = CEL()\n",
    "learning_rate = 1e-3\n",
    "model = LSTModel(encoder = encoder, \n",
    "                 decoder = decoder, \n",
    "                 encoder_optimizer = Adam(encoder.parameters(), lr = learning_rate), \n",
    "                 decoder_optimizer = Adam(decoder.parameters(), lr = learning_rate),\n",
    "                 loss_function = loss_func, \n",
    "                 eos_token = end_index, \n",
    "                 bos_token = start_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f0c9d0-6103-4fce-a3ac-8e694ff75b54",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40ae8e94-aa64-466e-820b-f1563aa47331",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [11] at entry 0 and [10] at entry 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_196075/4269462644.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m L_train, L_val = model.train_model(trainloader,\n\u001b[0m\u001b[1;32m      3\u001b[0m                       \u001b[0mvalloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0msave_every_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/INM706/Utilities/modelHandler.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, dataloader, valloader, max_epochs, save_every_epochs, ckp_name)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m########  START of TRAINING #########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m#####################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mid_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [11] at entry 0 and [10] at entry 2"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "L_train, L_val = model.train_model(trainloader,\n",
    "                      valloader,\n",
    "                      max_epochs = 10,\n",
    "                      save_every_epochs = 10,\n",
    "                      ckp_name = 'test')\n",
    "print(\"--------------------------------\")\n",
    "print(\"Time required: {}\".format(time.time()-start_time))\n",
    "      \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(L_train, linewidth = 3, label = \"Train\")\n",
    "ax.plot(L_val, linewidth = 3, label = \"Val\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded7f08-8449-430a-894e-0b25c1257349",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc40e5f-0eb9-4e39-a34c-9f45b926d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_ckp = \"test_enc_10.pth\"\n",
    "dec_ckp = \"test_dec_10.pth\"\n",
    "\n",
    "X, y, trans = model.evaluate_model(testloader, enc_ckp = enc_ckp, dec_ckp = dec_ckp)\n",
    "\n",
    "X_blue = dataset.translate(X,\"eng\")\n",
    "y_blue = dataset.translate(y,\"ita\")\n",
    "trans_blue = dataset.translate(trans,\"ita\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1938f746-3a25-4aab-ab77-ba115f9c4e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[234, 143,  54, 103, 255,  67, 318, 143,  54, 137],\n",
       "        [234, 143, 417, 277, 440, 273, 358, 143,  40, 119],\n",
       "        [234, 143, 417, 277, 440, 273, 358, 143,  40, 119],\n",
       "        [234, 190, 218, 290, 513, 143,   8, 158,  92, 212]], device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c72ad2e-6109-4583-85fb-db329379a0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'm', 'not', 'a', 'real', 'fish', 'I', 'm', 'just'],\n",
       " ['I', 'll', 'call', 'them', 'tomorrow', 'when', 'I', 'come', 'back'],\n",
       " ['I', 'll', 'call', 'them', 'tomorrow', 'when', 'I', 'come', 'back'],\n",
       " ['What', 'do', 'you', 'think', 'I', 've', 'been', 'doing']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_blue[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0c64a38-bf83-4000-9678-b139d2700b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It s not something anyone can do'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(X_blue[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c8f5b98-f67f-474f-a9fb-2c138db62978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nobody understands me': [['Nessuno', 'mi', 'capisce']],\n",
       " 'I m not a real fish I m just a': [['Non',\n",
       "   'sono',\n",
       "   'un',\n",
       "   'vero',\n",
       "   'pesce',\n",
       "   'non',\n",
       "   'sono',\n",
       "   'che',\n",
       "   'un',\n",
       "   'semplice']],\n",
       " 'I ll call them tomorrow when I come back': [['Li',\n",
       "   'chiamerò',\n",
       "   'domani',\n",
       "   'quando',\n",
       "   'ritorno'],\n",
       "  ['Le', 'chiamerò', 'domani', 'quando', 'ritorno']],\n",
       " 'What do you think I ve been doing': [['Cosa',\n",
       "   'credi',\n",
       "   'che',\n",
       "   'stessi',\n",
       "   'facendo']],\n",
       " 'I don t know what you mean': [['Non', 'so', 'cosa', 'intendi'],\n",
       "  ['Non', 'so', 'cosa', 'intende'],\n",
       "  ['Non', 'so', 'cosa', 'intendete']],\n",
       " 'It s not something anyone can do': [['Non',\n",
       "   'è',\n",
       "   'qualcosa',\n",
       "   'che',\n",
       "   'può',\n",
       "   'fare',\n",
       "   'chiunque']],\n",
       " 'I don t like you anymore': [['Non', 'mi', 'piaci', 'più']],\n",
       " 'It s a pity when somebody dies': [['È',\n",
       "   'un',\n",
       "   'peccato',\n",
       "   'quando',\n",
       "   'qualcuno',\n",
       "   'muore'],\n",
       "  ['È', 'un', 'peccato', 'quando', 'muore', 'qualcuno']],\n",
       " 'She s asking how that s possible': [['Chiede', 'come', 'sia', 'possibile'],\n",
       "  ['Lei', 'sta', 'chiedendo', 'come', 'sia', 'possibile'],\n",
       "  ['Sta', 'chiedendo', 'come', 'sia', 'possibile']],\n",
       " 'It may freeze next week': [['Potrebbe',\n",
       "   'ghiacciare',\n",
       "   'la',\n",
       "   'settimana',\n",
       "   'prossima'],\n",
       "  ['Può', 'ghiacciare', 'la', 'settimana', 'prossima']],\n",
       " 'Do you speak Italian': [['Parli', 'italiano'],\n",
       "  ['Tu', 'parli', 'italiano'],\n",
       "  ['Parla', 'italiano']],\n",
       " 'Someday I ll run like the wind': [['Un',\n",
       "   'giorno',\n",
       "   'correrò',\n",
       "   'come',\n",
       "   'il',\n",
       "   'vento']],\n",
       " 'No he s not my new boyfriend': [['No',\n",
       "   'non',\n",
       "   'è',\n",
       "   'il',\n",
       "   'mio',\n",
       "   'nuovo',\n",
       "   'ragazzo'],\n",
       "  ['No', 'non', 'è', 'il', 'mio', 'nuovo', 'fidanzato']],\n",
       " 'Whatever I do she says I can do better': [['Qualsiasi',\n",
       "   'cosa',\n",
       "   'faccia',\n",
       "   'lei',\n",
       "   'dice',\n",
       "   'che',\n",
       "   'posso',\n",
       "   'fare',\n",
       "   'meglio']],\n",
       " 'I want a boat that will take me far away': [['Voglio',\n",
       "   'una',\n",
       "   'barca',\n",
       "   'che',\n",
       "   'mi',\n",
       "   'porterà',\n",
       "   'molto',\n",
       "   'lontano',\n",
       "   'da',\n",
       "   'qui'],\n",
       "  ['Io',\n",
       "   'voglio',\n",
       "   'una',\n",
       "   'barca',\n",
       "   'che',\n",
       "   'mi',\n",
       "   'porterà',\n",
       "   'molto',\n",
       "   'lontano',\n",
       "   'da']],\n",
       " 'I m so fat': [['Sono', 'così', 'grasso'],\n",
       "  ['Sono', 'così', 'grassa'],\n",
       "  ['Io', 'sono', 'così', 'grasso'],\n",
       "  ['Io', 'sono', 'così', 'grassa']],\n",
       " 'I ll take him': [['Lo', 'prenderò'],\n",
       "  ['Io', 'lo', 'prenderò'],\n",
       "  ['Lo', 'porterò'],\n",
       "  ['Io', 'lo', 'porterò']],\n",
       " 'I suppose it s different when you think about it': [['Suppongo',\n",
       "   'sia',\n",
       "   'differente',\n",
       "   'se',\n",
       "   'ci',\n",
       "   'rifletti',\n",
       "   'sul',\n",
       "   'lungo',\n",
       "   'periodo']],\n",
       " 'Thank you very much': [['Grazie', 'mille']],\n",
       " 'People from Madrid are weird': [['La',\n",
       "   'gente',\n",
       "   'di',\n",
       "   'Madrid',\n",
       "   'è',\n",
       "   'strana'],\n",
       "  ['Le', 'persone', 'di', 'Madrid', 'sono', 'strane']],\n",
       " 'Did you miss me': [['Ti', 'sono', 'mancato'],\n",
       "  ['Ti', 'sono', 'mancata'],\n",
       "  ['Vi', 'sono', 'mancato'],\n",
       "  ['Vi', 'sono', 'mancata'],\n",
       "  ['Le', 'sono', 'mancato'],\n",
       "  ['Le', 'sono', 'mancata']],\n",
       " 'Except that here it s not so simple': [['Salvo',\n",
       "   'che',\n",
       "   'qui',\n",
       "   'non',\n",
       "   'è',\n",
       "   'così',\n",
       "   'semplice']],\n",
       " 'I think it is best not to be impolite': [['Penso',\n",
       "   'che',\n",
       "   'sia',\n",
       "   'meglio',\n",
       "   'non',\n",
       "   'essere',\n",
       "   'maleducati']],\n",
       " 'The archer killed the deer': [['L', 'arciere', 'uccise', 'il', 'cervo'],\n",
       "  ['L', 'arciere', 'ha', 'ucciso', 'il', 'cervo']],\n",
       " 'Tomorrow he will land on the moon': [['Domani',\n",
       "   'atterrerà',\n",
       "   'sulla',\n",
       "   'luna'],\n",
       "  ['Domani', 'lui', 'atterrerà', 'sulla', 'luna']],\n",
       " 'Don t open before the train stops': [['Non',\n",
       "   'aprire',\n",
       "   'prima',\n",
       "   'che',\n",
       "   'il',\n",
       "   'treno',\n",
       "   'sia',\n",
       "   'fermo']],\n",
       " 'The last person I told my idea to thought I': [['L',\n",
       "   'ultima',\n",
       "   'persona',\n",
       "   'a',\n",
       "   'cui',\n",
       "   'ho',\n",
       "   'raccontato',\n",
       "   'la',\n",
       "   'mia',\n",
       "   'idea'],\n",
       "  ['L',\n",
       "   'ultima',\n",
       "   'persona',\n",
       "   'a',\n",
       "   'cui',\n",
       "   'ho',\n",
       "   'raccontato',\n",
       "   'la',\n",
       "   'mia',\n",
       "   'idea']],\n",
       " 'I am not much of a traveller': [['Non', 'sono', 'un', 'gran', 'viaggiatore'],\n",
       "  ['Io', 'non', 'sono', 'un', 'gran', 'viaggiatore'],\n",
       "  ['Non', 'sono', 'una', 'gran', 'viaggiatrice'],\n",
       "  ['Io', 'non', 'sono', 'una', 'gran', 'viaggiatrice']],\n",
       " 'That was an evil bunny': [['Era', 'un', 'coniglietto', 'cattivo'],\n",
       "  ['Quello', 'era', 'un', 'coniglietto', 'cattivo']],\n",
       " 'In order to do that you have to take risks': [['Per',\n",
       "   'farlo',\n",
       "   'bisogna',\n",
       "   'correre',\n",
       "   'dei',\n",
       "   'rischi']],\n",
       " 'Who is it It s your mother': [['Chi', 'è', 'È', 'tua', 'madre']],\n",
       " 'It depends on the context': [['Dipende', 'dal', 'contesto']],\n",
       " 'I will be back soon': [['Torno', 'subito'],\n",
       "  ['Ritorno', 'presto'],\n",
       "  ['Ritornerò', 'presto'],\n",
       "  ['Tornerò', 'presto'],\n",
       "  ['Io', 'tornerò', 'presto'],\n",
       "  ['Io', 'ritornerò', 'presto'],\n",
       "  ['Sarò', 'presto', 'di', 'ritorno'],\n",
       "  ['Io', 'sarò', 'presto', 'di', 'ritorno']],\n",
       " 'One million people lost their lives in the war': [['Un',\n",
       "   'milione',\n",
       "   'di',\n",
       "   'persone',\n",
       "   'ha',\n",
       "   'perso',\n",
       "   'la',\n",
       "   'vita',\n",
       "   'durante',\n",
       "   'la']],\n",
       " 'I can only wait': [['Non', 'posso', 'far', 'altro', 'che', 'aspettare'],\n",
       "  ['Posso', 'solo', 'aspettare'],\n",
       "  ['Posso', 'solamente', 'aspettare'],\n",
       "  ['Posso', 'soltanto', 'aspettare']],\n",
       " 'In the 1950 s the Finns were cited as having': [['Negli',\n",
       "   'anni',\n",
       "   '50',\n",
       "   'i',\n",
       "   'finlandesi',\n",
       "   'sono',\n",
       "   'stati',\n",
       "   'citati',\n",
       "   'come',\n",
       "   'aventi']],\n",
       " 'I m at a loss for words': [['Sono', 'a', 'corto', 'di', 'parole'],\n",
       "  ['Sono', 'senza', 'parole']],\n",
       " 'I have nothing better to do': [['Non',\n",
       "   'ho',\n",
       "   'niente',\n",
       "   'di',\n",
       "   'meglio',\n",
       "   'da',\n",
       "   'fare']],\n",
       " 'They were left speechless': [['Erano', 'rimasti', 'senza', 'parole'],\n",
       "  ['Loro', 'erano', 'rimasti', 'senza', 'parole'],\n",
       "  ['Erano', 'rimaste', 'senza', 'parole'],\n",
       "  ['Loro', 'erano', 'rimaste', 'senza', 'parole']],\n",
       " 'This is what I would have said': [['Questo',\n",
       "   'è',\n",
       "   'ciò',\n",
       "   'che',\n",
       "   'avrei',\n",
       "   'detto'],\n",
       "  ['Questo', 'è', 'quello', 'che', 'avrei', 'detto']],\n",
       " 'Oh there s a butterfly': [['Oh', 'c', 'è', 'una', 'farfalla']],\n",
       " 'This is a pun': [['È', 'un', 'gioco', 'di', 'parole'],\n",
       "  ['Questo', 'è', 'un', 'gioco', 'di', 'parole']],\n",
       " 'That wasn t my intention': [['Non', 'era', 'mia', 'intenzione']],\n",
       " 'No I m not you are': [['No', 'non', 'sono', 'io', 'sei', 'tu']]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue_voc#['I ll call them tomorrow when I come back']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07bbb962-e74e-44ee-819e-e3b017ba897b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: Oh I m sorry\n",
      "Italian: Oh sono dispiaciuta\n",
      "Translation: Non\n"
     ]
    }
   ],
   "source": [
    "ids = 34\n",
    "print(\"English: \" + ' '.join(X_blue[ids]))\n",
    "print(\"Italian: \" + ' '.join(y_blue[ids]))\n",
    "print(\"Translation: \" + ' '.join(trans_blue[ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "151727aa-4cea-4463-bb00-d0423b5dd407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: We have five English classes a week\n",
      "Italian: Abbiamo cinque lezioni di inglese alla settimana\n",
      "Translation: Noi siamo un un un\n"
     ]
    }
   ],
   "source": [
    "ids = 12\n",
    "print(\"English: \" + ' '.join(X_blue[ids]))\n",
    "print(\"Italian: \" + ' '.join(y_blue[ids]))\n",
    "print(\"Translation: \" + ' '.join(trans_blue[ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cbf814a-beaf-42f3-813d-efdc885f568c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: He deceives others with his appearance\n",
      "Italian: Inganna gli altri con il suo aspetto\n",
      "Translation: Noi ha la la la\n"
     ]
    }
   ],
   "source": [
    "ids = 67\n",
    "print(\"English: \" + ' '.join(X_blue[ids]))\n",
    "print(\"Italian: \" + ' '.join(y_blue[ids]))\n",
    "print(\"Translation: \" + ' '.join(trans_blue[ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4125a20-9d03-4dce-a75b-4ccbd35a602c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
